{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bithoseoconda264274678644477794f47fddcf829f7c",
   "display_name": "Python 3.6.10 64-bit ('hoseo': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as  tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['bug', 'dragon', 'electricity', 'esp', 'evil', 'fairy', 'fight', 'fire', 'ghost', 'grass', 'ice', 'land', 'normal', 'posion', 'rock', 'steel', 'water']\nTotal number of categories: 17\nTotal number of images in dataset: 55588\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# folder_path = \"D:\\yun\\yun-python\\딥러닝(kmooc 연습)\\포켓몬 이미지\"\n",
    "folder_path = \"D:\\yun\\yun-python\\deeplearning\\pokemon-train-image\"\n",
    "folder_list = os.listdir(folder_path)\n",
    "print(folder_list)\n",
    "print(f'Total number of categories: {len(folder_list)}')\n",
    "\n",
    "counts = {}\n",
    "for c in folder_list:\n",
    "    counts[c] = len(os.listdir(os.path.join(folder_path, c)))\n",
    "    \n",
    "print(f'Total number of images in dataset: {sum(list(counts.values()))}')\n",
    "\n",
    "# categories=['강철', '격투', '고스트', '노멀', '독', '드래곤', '땅', '물', '바위', '벌레', '불꽃', '악', '얼음', '에스퍼', '전기', '페어리', '풀']\n",
    "\n",
    "categories=['bug', 'dragon', 'electricity', 'esp', 'evil', 'fairy', 'fight', 'fire', 'ghost', 'glue', 'ice', 'land', 'normal', 'posion', 'rock', 'steel', 'water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('water', 6410), ('normal', 5096), ('fire', 4101), ('bug', 4001), ('grass', 3916), ('land', 3448), ('esp', 3177), ('posion', 3086), ('electricity', 3046), ('rock', 2905), ('fight', 2904), ('ice', 2670), ('dragon', 2397), ('ghost', 2356), ('steel', 2305), ('evil', 2072), ('fairy', 1698)]\n"
     ]
    }
   ],
   "source": [
    "imbalanced = sorted(counts.items(), key = lambda x: x[1], reverse = True)\n",
    "print(imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caltech_dir = \"..\\deeplearning\\pokemon-image\"\n",
    "caltech_dir = \"pokemon-train-image\"\n",
    "categories=['bug', 'dragon', 'electricity', 'esp', 'evil', 'fairy', 'fight', 'fire', 'ghost', 'glue', 'ice', 'land', 'normal', 'posion', 'rock', 'steel', 'water']\n",
    "nb_classes = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !dir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 55588 images belonging to 17 classes.\n",
      "Found 55588 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "# 이미지 전처리\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      vertical_flip=True,\n",
    "      validation_split=0.2,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        # 타깃 디렉터리\n",
    "        caltech_dir,\n",
    "        # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
    "        target_size=(150, 150),\n",
    "        shuffle=True,\n",
    "        batch_size=40,\n",
    "        class_mode='categorical')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range = 40,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 shear_range=0.2,\n",
    "                                 zoom_range=0.2,\n",
    "                                 horizontal_flip=False,\n",
    "                                 vertical_flip=True,\n",
    "                                 fill_mode='nearest')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "                                          caltech_dir,\n",
    "                                          target_size=(150,150),\n",
    "                                          batch_size=40,\n",
    "                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),padding='same', input_shape=(150,150,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3),padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3),padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3),padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(17, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 학습 설정\n",
    "sgd = optimizers.SGD(learning_rate=0.01, momentum=0.9 , nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=sgd,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-8c8b79949d95>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/150\n",
      "200/200 [==============================] - 694s 3s/step - loss: 2.7573 - accuracy: 0.1700 - val_loss: 2.6863 - val_accuracy: 0.1593\n",
      "Epoch 2/150\n",
      "200/200 [==============================] - 693s 3s/step - loss: 2.5684 - accuracy: 0.2130 - val_loss: 2.6398 - val_accuracy: 0.1868\n",
      "Epoch 3/150\n",
      "200/200 [==============================] - 725s 4s/step - loss: 2.5229 - accuracy: 0.2300 - val_loss: 2.5966 - val_accuracy: 0.2025\n",
      "Epoch 4/150\n",
      "200/200 [==============================] - 709s 4s/step - loss: 2.4876 - accuracy: 0.2311 - val_loss: 2.6535 - val_accuracy: 0.1882\n",
      "Epoch 5/150\n",
      "200/200 [==============================] - 679s 3s/step - loss: 2.4597 - accuracy: 0.2376 - val_loss: 2.5002 - val_accuracy: 0.2364\n",
      "Epoch 6/150\n",
      "200/200 [==============================] - 668s 3s/step - loss: 2.4257 - accuracy: 0.2519 - val_loss: 2.5457 - val_accuracy: 0.2029\n",
      "Epoch 7/150\n",
      "200/200 [==============================] - 671s 3s/step - loss: 2.4151 - accuracy: 0.2541 - val_loss: 2.4194 - val_accuracy: 0.2343\n",
      "Epoch 8/150\n",
      "200/200 [==============================] - 665s 3s/step - loss: 2.4110 - accuracy: 0.2512 - val_loss: 2.4533 - val_accuracy: 0.2532\n",
      "Epoch 9/150\n",
      "200/200 [==============================] - 664s 3s/step - loss: 2.3766 - accuracy: 0.2719 - val_loss: 2.4819 - val_accuracy: 0.2300\n",
      "Epoch 10/150\n",
      "200/200 [==============================] - 667s 3s/step - loss: 2.3571 - accuracy: 0.2689 - val_loss: 2.4876 - val_accuracy: 0.2175\n",
      "Epoch 11/150\n",
      "200/200 [==============================] - 667s 3s/step - loss: 2.3646 - accuracy: 0.2627 - val_loss: 2.3299 - val_accuracy: 0.2696\n",
      "Epoch 12/150\n",
      "200/200 [==============================] - 667s 3s/step - loss: 2.3315 - accuracy: 0.2756 - val_loss: 2.3134 - val_accuracy: 0.2861\n",
      "Epoch 13/150\n",
      "200/200 [==============================] - 667s 3s/step - loss: 2.3495 - accuracy: 0.2719 - val_loss: 2.3578 - val_accuracy: 0.2629\n",
      "Epoch 14/150\n",
      "200/200 [==============================] - 692s 3s/step - loss: 2.3479 - accuracy: 0.2632 - val_loss: 2.3045 - val_accuracy: 0.2736\n",
      "Epoch 15/150\n",
      "200/200 [==============================] - 687s 3s/step - loss: 2.3218 - accuracy: 0.2750 - val_loss: 2.3632 - val_accuracy: 0.2725\n",
      "Epoch 16/150\n",
      "200/200 [==============================] - 690s 3s/step - loss: 2.3330 - accuracy: 0.2766 - val_loss: 2.3451 - val_accuracy: 0.2725\n",
      "Epoch 17/150\n",
      "200/200 [==============================] - 687s 3s/step - loss: 2.3023 - accuracy: 0.2830 - val_loss: 2.3177 - val_accuracy: 0.2632\n",
      "Epoch 18/150\n",
      "200/200 [==============================] - 687s 3s/step - loss: 2.2986 - accuracy: 0.2778 - val_loss: 2.3889 - val_accuracy: 0.2621\n",
      "Epoch 19/150\n",
      "200/200 [==============================] - 715s 4s/step - loss: 2.2980 - accuracy: 0.2767 - val_loss: 2.3033 - val_accuracy: 0.2754\n",
      "Epoch 20/150\n",
      "200/200 [==============================] - 697s 3s/step - loss: 2.2961 - accuracy: 0.2836 - val_loss: 2.2639 - val_accuracy: 0.2893\n",
      "Epoch 21/150\n",
      "200/200 [==============================] - 674s 3s/step - loss: 2.2856 - accuracy: 0.2850 - val_loss: 2.3132 - val_accuracy: 0.2807\n",
      "Epoch 22/150\n",
      "200/200 [==============================] - 695s 3s/step - loss: 2.2827 - accuracy: 0.2863 - val_loss: 2.5182 - val_accuracy: 0.2179\n",
      "Epoch 23/150\n",
      "200/200 [==============================] - 694s 3s/step - loss: 2.2740 - accuracy: 0.2886 - val_loss: 2.2682 - val_accuracy: 0.2818\n",
      "Epoch 24/150\n",
      "200/200 [==============================] - 679s 3s/step - loss: 2.2803 - accuracy: 0.2850 - val_loss: 2.4932 - val_accuracy: 0.2300\n",
      "Epoch 25/150\n",
      "200/200 [==============================] - 690s 3s/step - loss: 2.2408 - accuracy: 0.2979 - val_loss: 2.2992 - val_accuracy: 0.2693\n",
      "Epoch 26/150\n",
      "200/200 [==============================] - 682s 3s/step - loss: 2.2630 - accuracy: 0.2914 - val_loss: 2.3051 - val_accuracy: 0.2789\n",
      "Epoch 27/150\n",
      "200/200 [==============================] - 693s 3s/step - loss: 2.2406 - accuracy: 0.2949 - val_loss: 2.1964 - val_accuracy: 0.3157\n",
      "Epoch 28/150\n",
      "200/200 [==============================] - 693s 3s/step - loss: 2.2530 - accuracy: 0.2959 - val_loss: 2.2738 - val_accuracy: 0.2836\n",
      "Epoch 29/150\n",
      "200/200 [==============================] - 690s 3s/step - loss: 2.2513 - accuracy: 0.2970 - val_loss: 2.2060 - val_accuracy: 0.3175\n",
      "Epoch 30/150\n",
      "200/200 [==============================] - 686s 3s/step - loss: 2.2293 - accuracy: 0.3006 - val_loss: 2.1516 - val_accuracy: 0.3171\n",
      "Epoch 31/150\n",
      "200/200 [==============================] - 692s 3s/step - loss: 2.2155 - accuracy: 0.3038 - val_loss: 2.2923 - val_accuracy: 0.2886\n",
      "Epoch 32/150\n",
      "200/200 [==============================] - 698s 3s/step - loss: 2.2431 - accuracy: 0.2993 - val_loss: 2.4011 - val_accuracy: 0.2518\n",
      "Epoch 33/150\n",
      "200/200 [==============================] - 689s 3s/step - loss: 2.2215 - accuracy: 0.3036 - val_loss: 2.1856 - val_accuracy: 0.3036\n",
      "Epoch 34/150\n",
      "200/200 [==============================] - 763s 4s/step - loss: 2.1917 - accuracy: 0.3077 - val_loss: 2.1971 - val_accuracy: 0.3043\n",
      "Epoch 35/150\n",
      "200/200 [==============================] - 706s 4s/step - loss: 2.2096 - accuracy: 0.3041 - val_loss: 2.1920 - val_accuracy: 0.3136\n",
      "Epoch 36/150\n",
      "200/200 [==============================] - 676s 3s/step - loss: 2.1961 - accuracy: 0.3103 - val_loss: 2.2579 - val_accuracy: 0.2982\n",
      "Epoch 37/150\n",
      "200/200 [==============================] - 700s 4s/step - loss: 2.1914 - accuracy: 0.3027 - val_loss: 2.1702 - val_accuracy: 0.3189\n",
      "Epoch 38/150\n",
      "200/200 [==============================] - 697s 3s/step - loss: 2.1968 - accuracy: 0.3121 - val_loss: 2.1893 - val_accuracy: 0.3111\n",
      "Epoch 39/150\n",
      "200/200 [==============================] - 685s 3s/step - loss: 2.1911 - accuracy: 0.3103 - val_loss: 2.7290 - val_accuracy: 0.1554\n",
      "Epoch 40/150\n",
      "200/200 [==============================] - 695s 3s/step - loss: 2.2005 - accuracy: 0.3106 - val_loss: 2.1486 - val_accuracy: 0.3261\n",
      "Epoch 41/150\n",
      "200/200 [==============================] - 694s 3s/step - loss: 2.1877 - accuracy: 0.3165 - val_loss: 2.1560 - val_accuracy: 0.3225\n",
      "Epoch 42/150\n",
      "200/200 [==============================] - 684s 3s/step - loss: 2.1633 - accuracy: 0.3184 - val_loss: 2.1781 - val_accuracy: 0.3061\n",
      "Epoch 43/150\n",
      "200/200 [==============================] - 711s 4s/step - loss: 2.1530 - accuracy: 0.3180 - val_loss: 2.1524 - val_accuracy: 0.3239\n",
      "Epoch 44/150\n",
      "200/200 [==============================] - 717s 4s/step - loss: 2.1630 - accuracy: 0.3216 - val_loss: 2.3500 - val_accuracy: 0.2725\n",
      "Epoch 45/150\n",
      "200/200 [==============================] - 717s 4s/step - loss: 2.1548 - accuracy: 0.3199 - val_loss: 2.1791 - val_accuracy: 0.3061\n",
      "Epoch 46/150\n",
      "200/200 [==============================] - 717s 4s/step - loss: 2.1430 - accuracy: 0.3299 - val_loss: 2.2781 - val_accuracy: 0.2811\n",
      "Epoch 47/150\n",
      "200/200 [==============================] - 712s 4s/step - loss: 2.1528 - accuracy: 0.3212 - val_loss: 2.1118 - val_accuracy: 0.3379\n",
      "Epoch 48/150\n",
      "200/200 [==============================] - 711s 4s/step - loss: 2.1370 - accuracy: 0.3315 - val_loss: 2.3366 - val_accuracy: 0.2804\n",
      "Epoch 49/150\n",
      "200/200 [==============================] - 719s 4s/step - loss: 2.1473 - accuracy: 0.3285 - val_loss: 2.2819 - val_accuracy: 0.2718\n",
      "Epoch 50/150\n",
      "200/200 [==============================] - 717s 4s/step - loss: 2.1298 - accuracy: 0.3316 - val_loss: 2.1467 - val_accuracy: 0.3329\n",
      "Epoch 51/150\n",
      "200/200 [==============================] - 713s 4s/step - loss: 2.1406 - accuracy: 0.3262 - val_loss: 2.2087 - val_accuracy: 0.3036\n",
      "Epoch 52/150\n",
      "200/200 [==============================] - 714s 4s/step - loss: 2.1348 - accuracy: 0.3269 - val_loss: 2.1411 - val_accuracy: 0.3246\n",
      "Epoch 53/150\n",
      "200/200 [==============================] - 710s 4s/step - loss: 2.1356 - accuracy: 0.3294 - val_loss: 2.1137 - val_accuracy: 0.3318\n",
      "Epoch 54/150\n",
      "200/200 [==============================] - 710s 4s/step - loss: 2.1084 - accuracy: 0.3369 - val_loss: 2.0948 - val_accuracy: 0.3289\n",
      "Epoch 55/150\n",
      "200/200 [==============================] - 714s 4s/step - loss: 2.0855 - accuracy: 0.3336 - val_loss: 2.1135 - val_accuracy: 0.3357\n",
      "Epoch 56/150\n",
      "200/200 [==============================] - 717s 4s/step - loss: 2.1054 - accuracy: 0.3392 - val_loss: 2.0940 - val_accuracy: 0.3396\n",
      "Epoch 57/150\n",
      "200/200 [==============================] - 717s 4s/step - loss: 2.1211 - accuracy: 0.3345 - val_loss: 3.9190 - val_accuracy: 0.0864\n",
      "Epoch 58/150\n",
      "200/200 [==============================] - 718s 4s/step - loss: 2.1365 - accuracy: 0.3290 - val_loss: 2.1751 - val_accuracy: 0.3204\n",
      "Epoch 59/150\n",
      "200/200 [==============================] - 719s 4s/step - loss: 2.0941 - accuracy: 0.3400 - val_loss: 2.2290 - val_accuracy: 0.3007\n",
      "Epoch 60/150\n",
      "200/200 [==============================] - 718s 4s/step - loss: 2.1157 - accuracy: 0.3350 - val_loss: 2.0720 - val_accuracy: 0.3525\n",
      "Epoch 61/150\n",
      "200/200 [==============================] - 715s 4s/step - loss: 2.1020 - accuracy: 0.3370 - val_loss: 2.1003 - val_accuracy: 0.3496\n",
      "Epoch 62/150\n",
      "200/200 [==============================] - 718s 4s/step - loss: 2.0685 - accuracy: 0.3499 - val_loss: 2.1591 - val_accuracy: 0.3279\n",
      "Epoch 63/150\n",
      "200/200 [==============================] - 715s 4s/step - loss: 2.0837 - accuracy: 0.3435 - val_loss: 2.0923 - val_accuracy: 0.3450\n",
      "Epoch 64/150\n",
      "200/200 [==============================] - 715s 4s/step - loss: 2.0884 - accuracy: 0.3440 - val_loss: 2.0212 - val_accuracy: 0.3586\n",
      "Epoch 65/150\n",
      "200/200 [==============================] - 714s 4s/step - loss: 2.0618 - accuracy: 0.3496 - val_loss: 2.0899 - val_accuracy: 0.3275\n",
      "Epoch 66/150\n",
      "200/200 [==============================] - 716s 4s/step - loss: 2.0542 - accuracy: 0.3512 - val_loss: 2.1246 - val_accuracy: 0.3279\n",
      "Epoch 67/150\n",
      "200/200 [==============================] - 716s 4s/step - loss: 2.0490 - accuracy: 0.3529 - val_loss: 2.0923 - val_accuracy: 0.3371\n",
      "Epoch 68/150\n",
      "200/200 [==============================] - 717s 4s/step - loss: 2.0562 - accuracy: 0.3530 - val_loss: 2.0552 - val_accuracy: 0.3504\n",
      "Epoch 69/150\n",
      "200/200 [==============================] - 712s 4s/step - loss: 2.0498 - accuracy: 0.3516 - val_loss: 2.0271 - val_accuracy: 0.3568\n",
      "Epoch 70/150\n",
      "200/200 [==============================] - 711s 4s/step - loss: 2.0533 - accuracy: 0.3638 - val_loss: 2.0279 - val_accuracy: 0.3607\n",
      "Epoch 71/150\n",
      "200/200 [==============================] - 712s 4s/step - loss: 2.0627 - accuracy: 0.3525 - val_loss: 2.0300 - val_accuracy: 0.3489\n",
      "Epoch 72/150\n",
      "200/200 [==============================] - 715s 4s/step - loss: 2.0422 - accuracy: 0.3500 - val_loss: 2.0524 - val_accuracy: 0.3432\n",
      "Epoch 73/150\n",
      "200/200 [==============================] - 714s 4s/step - loss: 2.0229 - accuracy: 0.3602 - val_loss: 2.4694 - val_accuracy: 0.2486\n",
      "Epoch 74/150\n",
      "200/200 [==============================] - 714s 4s/step - loss: 2.0176 - accuracy: 0.3663 - val_loss: 2.0859 - val_accuracy: 0.3396\n",
      "Epoch 75/150\n",
      "200/200 [==============================] - 700s 3s/step - loss: 2.0437 - accuracy: 0.3623 - val_loss: 2.1145 - val_accuracy: 0.3279\n",
      "Epoch 76/150\n",
      "200/200 [==============================] - 691s 3s/step - loss: 2.0541 - accuracy: 0.3520 - val_loss: 2.0650 - val_accuracy: 0.3514\n",
      "Epoch 77/150\n",
      "200/200 [==============================] - 694s 3s/step - loss: 2.0247 - accuracy: 0.3676 - val_loss: 2.1349 - val_accuracy: 0.3307\n",
      "Epoch 78/150\n",
      "200/200 [==============================] - 695s 3s/step - loss: 2.0413 - accuracy: 0.3525 - val_loss: 2.2748 - val_accuracy: 0.2896\n",
      "Epoch 79/150\n",
      "200/200 [==============================] - 696s 3s/step - loss: 2.0070 - accuracy: 0.3688 - val_loss: 2.0709 - val_accuracy: 0.3486\n",
      "Epoch 80/150\n",
      "200/200 [==============================] - 696s 3s/step - loss: 2.0320 - accuracy: 0.3646 - val_loss: 2.2241 - val_accuracy: 0.2939\n",
      "Epoch 81/150\n",
      "200/200 [==============================] - 688s 3s/step - loss: 2.0198 - accuracy: 0.3590 - val_loss: 2.2114 - val_accuracy: 0.3171\n",
      "Epoch 82/150\n",
      "200/200 [==============================] - 679s 3s/step - loss: 2.0220 - accuracy: 0.3584 - val_loss: 2.0254 - val_accuracy: 0.3561\n",
      "Epoch 83/150\n",
      "200/200 [==============================] - 680s 3s/step - loss: 2.0183 - accuracy: 0.3644 - val_loss: 2.1129 - val_accuracy: 0.3368\n",
      "Epoch 84/150\n",
      "200/200 [==============================] - 680s 3s/step - loss: 2.0174 - accuracy: 0.3623 - val_loss: 2.3474 - val_accuracy: 0.2689\n",
      "Epoch 85/150\n",
      "200/200 [==============================] - 680s 3s/step - loss: 1.9920 - accuracy: 0.3715 - val_loss: 1.9790 - val_accuracy: 0.3664\n",
      "Epoch 86/150\n",
      "200/200 [==============================] - 691s 3s/step - loss: 1.9975 - accuracy: 0.3719 - val_loss: 2.1371 - val_accuracy: 0.3443\n",
      "Epoch 87/150\n",
      "200/200 [==============================] - 692s 3s/step - loss: 1.9930 - accuracy: 0.3710 - val_loss: 1.9469 - val_accuracy: 0.3829\n",
      "Epoch 88/150\n",
      "200/200 [==============================] - 699s 3s/step - loss: 1.9752 - accuracy: 0.3798 - val_loss: 2.2855 - val_accuracy: 0.2875\n",
      "Epoch 89/150\n",
      "200/200 [==============================] - 717s 4s/step - loss: 1.9901 - accuracy: 0.3760 - val_loss: 1.9187 - val_accuracy: 0.3957\n",
      "Epoch 90/150\n",
      "200/200 [==============================] - 716s 4s/step - loss: 1.9695 - accuracy: 0.3806 - val_loss: 2.0281 - val_accuracy: 0.3543\n",
      "Epoch 91/150\n",
      "200/200 [==============================] - 689s 3s/step - loss: 1.9760 - accuracy: 0.3749 - val_loss: 1.9086 - val_accuracy: 0.4096\n",
      "Epoch 92/150\n",
      "200/200 [==============================] - 686s 3s/step - loss: 1.9615 - accuracy: 0.3854 - val_loss: 2.0421 - val_accuracy: 0.3657\n",
      "Epoch 93/150\n",
      "200/200 [==============================] - 699s 3s/step - loss: 1.9685 - accuracy: 0.3817 - val_loss: 2.0269 - val_accuracy: 0.3611\n",
      "Epoch 94/150\n",
      "200/200 [==============================] - 705s 4s/step - loss: 1.9627 - accuracy: 0.3826 - val_loss: 2.1064 - val_accuracy: 0.3421\n",
      "Epoch 95/150\n",
      "200/200 [==============================] - 751s 4s/step - loss: 1.9515 - accuracy: 0.3842 - val_loss: 2.0779 - val_accuracy: 0.3454\n",
      "Epoch 96/150\n",
      "200/200 [==============================] - 707s 4s/step - loss: 1.9462 - accuracy: 0.3875 - val_loss: 1.9562 - val_accuracy: 0.3821\n",
      "Epoch 97/150\n",
      "200/200 [==============================] - 698s 3s/step - loss: 1.9578 - accuracy: 0.3856 - val_loss: 2.1188 - val_accuracy: 0.3268\n",
      "Epoch 98/150\n",
      "200/200 [==============================] - 703s 4s/step - loss: 1.9703 - accuracy: 0.3874 - val_loss: 1.9127 - val_accuracy: 0.3971\n",
      "Epoch 99/150\n",
      "200/200 [==============================] - 687s 3s/step - loss: 1.9558 - accuracy: 0.3877 - val_loss: 1.8822 - val_accuracy: 0.4064\n",
      "Epoch 100/150\n",
      "200/200 [==============================] - 688s 3s/step - loss: 1.9485 - accuracy: 0.3826 - val_loss: 1.9136 - val_accuracy: 0.3971\n",
      "Epoch 101/150\n",
      "200/200 [==============================] - 659s 3s/step - loss: 1.9225 - accuracy: 0.3950 - val_loss: 2.1695 - val_accuracy: 0.3271\n",
      "Epoch 102/150\n",
      "200/200 [==============================] - 668s 3s/step - loss: 1.9310 - accuracy: 0.3866 - val_loss: 2.3882 - val_accuracy: 0.2832\n",
      "Epoch 103/150\n",
      "200/200 [==============================] - 692s 3s/step - loss: 1.9114 - accuracy: 0.4006 - val_loss: 2.0325 - val_accuracy: 0.3571\n",
      "Epoch 104/150\n",
      "200/200 [==============================] - 698s 3s/step - loss: 1.9201 - accuracy: 0.3915 - val_loss: 2.1483 - val_accuracy: 0.3536\n",
      "Epoch 105/150\n",
      "200/200 [==============================] - 713s 4s/step - loss: 1.9024 - accuracy: 0.3988 - val_loss: 1.8884 - val_accuracy: 0.4086\n",
      "Epoch 106/150\n",
      "200/200 [==============================] - 646s 3s/step - loss: 1.9088 - accuracy: 0.3988 - val_loss: 2.0553 - val_accuracy: 0.3568\n",
      "Epoch 107/150\n",
      "200/200 [==============================] - 645s 3s/step - loss: 1.9339 - accuracy: 0.3951 - val_loss: 2.0070 - val_accuracy: 0.3732\n",
      "Epoch 108/150\n",
      "200/200 [==============================] - 654s 3s/step - loss: 1.8890 - accuracy: 0.4096 - val_loss: 1.8630 - val_accuracy: 0.4175\n",
      "Epoch 109/150\n",
      "200/200 [==============================] - 656s 3s/step - loss: 1.9069 - accuracy: 0.4049 - val_loss: 1.9622 - val_accuracy: 0.3879\n",
      "Epoch 110/150\n",
      "200/200 [==============================] - 647s 3s/step - loss: 1.9127 - accuracy: 0.4004 - val_loss: 1.8573 - val_accuracy: 0.4075\n",
      "Epoch 111/150\n",
      "200/200 [==============================] - 668s 3s/step - loss: 1.9017 - accuracy: 0.4081 - val_loss: 1.9765 - val_accuracy: 0.3814\n",
      "Epoch 112/150\n",
      "200/200 [==============================] - 689s 3s/step - loss: 1.9152 - accuracy: 0.3968 - val_loss: 2.1133 - val_accuracy: 0.3414\n",
      "Epoch 113/150\n",
      "200/200 [==============================] - 689s 3s/step - loss: 1.8997 - accuracy: 0.4006 - val_loss: 1.9466 - val_accuracy: 0.4011\n",
      "Epoch 114/150\n",
      "200/200 [==============================] - 371s 2s/step - loss: 1.8924 - accuracy: 0.4027 - val_loss: 1.8495 - val_accuracy: 0.4314\n",
      "Epoch 115/150\n",
      " 56/200 [=======>......................] - ETA: 5:14 - loss: 1.9089 - accuracy: 0.3879"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8c8b79949d95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     validation_steps=70)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\hoseo\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\hoseo\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1829\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\hoseo\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\hoseo\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\hoseo\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\hoseo\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\hoseo\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\hoseo\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\hoseo\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\hoseo\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\hoseo\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fig_generator\n",
    "model.fit_generator(\n",
    "    generator,\n",
    "    steps_per_epoch=200,\n",
    "    epochs=150,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}