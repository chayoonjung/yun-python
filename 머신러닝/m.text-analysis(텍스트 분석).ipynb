{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영화 리뷰 감성 분석 (감성평가)  (교재 p.416~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files('data-files/aclImdb/train') #지정된 폴더의 하위폴더가 타겟 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n",
      "25000\n",
      "b\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\"\n",
      "['neg', 'pos']\n",
      "[1 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(reviews_train.keys())\n",
    "print(len(reviews_train['data']))\n",
    "print(reviews_train['data'][0])\n",
    "print(reviews_train['target_names'])\n",
    "print(reviews_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = reviews_train['data'], reviews_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 [12623, 24836, 13781, 1326, 8484] 5000\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "size = int(len(X_train) * 0.2)            # 25000건중 20%만 자르는 과정\n",
    "# idxes = np.random.randint(0, len(X_train), size)  # 0부터 X_train갯수 까지중 size만큼 랜덤으로 뽑는다. 20% 데이터 샘플링 (복원추출)\n",
    "idxes = random.sample(range(len(X_train)), size)  # 랜덤으로 추출 // 20% 데이터 샘플링(비복원추출)\n",
    "print( len(idxes), idxes[:5], len(np.unique(idxes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000,), (5000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train2, y_train2 = [X_train[i] for i in idxes],[y_train[i] for i in idxes]\n",
    "X_train2, y_train2 = np.array(X_train)[idxes], np.array(y_train)[idxes]\n",
    "X_train2.shape, y_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Friz Freleng's 'Speedy Gonzalez' was the second cartoon to feature the title character after Robert McKimson's 'Cat-tails for Two'. In that cartoon, Speedy has been an ugly little creature with a big gold tooth but by his second appearance the famous design had already been adopted. Despite looking significantly more handsome, Speedy never developed into much of a character. A big hat, tremendous speed and a bad Mexican accent do not a classic character make and that's pretty much all Speedy ever had going for him. Nevertheless, the cocky little mouse proved enormously popular and went on to star in many shorts including some truly abysmal films from the studio's latter days. While these early Speedy shorts are better than those later atrocities in which he was frequently (rather oddly) paired up with Daffy Duck, they still leave much to be desired, relying on predictable gags usually based around a similar chase formula. In this self-titled episode, Speedy is recruited by some other mice to steal cheese for them from the local factory which happens to be guarded by Sylvester the cat. Although he brings the extra weight of a star turn to the cartoon, Sylvester's role here could just as easily been filled by any other generic cartoon cat. His personality is sapped by his being forced into the predictable. undemanding role of pursuer. This was always a problem in the Tweety cartoons too but Speedy makes an even duller adversary thanks to his detestable cockiness and the blatant impossibility of his capture. Poor old Sylvester would be forced to appear alongside Speedy for many years to come. Despite it following a pretty basic formula and featuring minimal laughs, 'Speedy Gonzalez' won an Oscar and a thoroughly undeserving star was born.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2[1]   #데이터가 html로 되어 있음. <br /><br />\n",
    "X_train2 = np.array([x.replace(b'<br />', b'') for x in X_train2])   #반복문 돌리며 진행(내포방식)     #자바스크립트 정규표현식 참조할것!\n",
    "# 또는 아래방식으로도 진행 가능\n",
    "# X_train22 = map(lambda x : x.replace(b'<br />', b''), X_train2)  \n",
    "# X_train2 = np.array(list(X_train2))\n",
    "\n",
    "X_train2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2505, 2495], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불균형성\n",
    "np.unique(y_train2, return_counts=True)  # 값이 바뀌는 이유 => 랜덤값//  random.seed를 줘야 같은조건으로 동작된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files('data-files/aclImdb/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = reviews_test['data'], reviews_test['target']\n",
    "size = int(len(X_test) * 0.2 )\n",
    "idxes = random.sample(range(len(X_test)),size)\n",
    "len(np.unique(idxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = np.array( [X_test[idx] for idx in idxes])\n",
    "y_test2 = np.array( [y_test[idx] for idx in idxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2544, 2456], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test2, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = np.array([ x.replace(b'<br />', b'') for x in X_test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"What a great film! I never knew much about Buddy Holly, but was familiar with his lively and fun music. This is a wonderful biography of someone who helped change the music in the 1950's. Although I never cared for Gary Bussey, he was fabulous as Buddy Holly! I don't know how accurate the movie is, but assume at least for the most part it is accurate, which makes the movie all the more interesting. The music throughout the movie just adds the pizazz to this biography. I don't think I would change a thing in this film, it was all good! What a difference in the stars from the 50's to todays music stars. How can you compare someone like Buddy Holly to Justin Timberlake? or any of the other popular singers of this generation?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " BOW example  (빈도 가중치)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = [\"The fool doth think he is wise\",\n",
    "              \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer() # 문장 -> 단어사전 만들기 + 단어별 빈도수 계산\n",
    "cv.fit(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 9,\n",
       " 'fool': 3,\n",
       " 'doth': 2,\n",
       " 'think': 10,\n",
       " 'he': 4,\n",
       " 'is': 6,\n",
       " 'wise': 12,\n",
       " 'but': 1,\n",
       " 'man': 8,\n",
       " 'knows': 7,\n",
       " 'himself': 5,\n",
       " 'to': 11,\n",
       " 'be': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be',\n",
       " 'but',\n",
       " 'doth',\n",
       " 'fool',\n",
       " 'he',\n",
       " 'himself',\n",
       " 'is',\n",
       " 'knows',\n",
       " 'man',\n",
       " 'the',\n",
       " 'think',\n",
       " 'to',\n",
       " 'wise']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cv.vocabulary_, key=lambda key: cv.vocabulary_[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>but</th>\n",
       "      <th>doth</th>\n",
       "      <th>fool</th>\n",
       "      <th>he</th>\n",
       "      <th>himself</th>\n",
       "      <th>is</th>\n",
       "      <th>knows</th>\n",
       "      <th>man</th>\n",
       "      <th>the</th>\n",
       "      <th>think</th>\n",
       "      <th>to</th>\n",
       "      <th>wise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   be  but  doth  fool  he  himself  is  knows  man  the  think  to  wise\n",
       "0   0    0     1     1   1        0   1      0    0    1      1   0     1\n",
       "1   1    1     0     1   0        1   0      1    1    1      0   1     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# print( cv.transform(test_words) )\n",
    "print(cv.transform(test_words).toarray())\n",
    "pd.DataFrame(cv.transform(test_words).toarray(), \n",
    "             columns=sorted(cv.vocabulary_, key=lambda key: cv.vocabulary_[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer() #문자열을 숫자열로 변형\n",
    "cv.fit(X_train2)\n",
    "X_train3 = cv.transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 38559)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train3.toarray().shape)\n",
    "print(X_train3.toarray()[:5])\n",
    "# print(X_train3)\n",
    "# print(cv.vocabulary_)\n",
    "# cv.get_feature_names()   #정렬된 컬럼 이름들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score #감성평가 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9938\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs',max_iter=10000, C=0.1)\n",
    "lr.fit(X_train3, y_train2)\n",
    "print(lr.score(X_train3, y_train2))\n",
    "# print(lr.score(X_test3, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test3 = cv.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8602\n"
     ]
    }
   ],
   "source": [
    "print(lr.score(X_test3, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9188213820147895\n",
      "0.928311713836478\n"
     ]
    }
   ],
   "source": [
    "print(average_precision_score(y_test2,lr.predict_proba(X_test3)[:,1]))\n",
    "print(roc_auc_score(y_test2,lr.predict_proba(X_test3)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11326\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=5) #5회 이상 발견된 데이터만 포함\n",
    "cv.fit(X_train2)\n",
    "print(len(cv.get_feature_names()))\n",
    "X_train3=cv.transform(X_train2)\n",
    "X_test3=cv.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9884\n",
      "0.861\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=10000, C=0.1)\n",
    "lr.fit(X_train3,y_train2)\n",
    "print(lr.score(X_train3, y_train2))\n",
    "print(lr.score(X_test3, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'I saw this not too long ago, and I must say: This movie is terrible. I watch crappy movies for fun. Scarecreow is not fun. Scarecrow is stupid. You have an incredibly corny villain that enjoys screaming awful puns as he kills his victims(actually worse than the one contained in this sentence). He has his hard luck story that he uses to justify his killings. \"Everyone picks on me. The only girl that thinks I\\'m not trailer-trash likes one of the guys that pick on me. I want to kill everybody. Wah.\" OK, I\\'m exaggerating. But the premise to this movie alone is enough to put it near the bottom of the list of crappy movies.Adding to what I just said, the kid\\'s mom is promiscuous, he walks in on his mother and her current boyfriend getting it on, mom\\'s boyfriend tells him to leave, kid refuses, insisting that he isn\\'t going to leave his own house. Boyfriend chases kid into corn field. He kills kid right in front of mom, mom screams in terror, boyfriend is like, \"OMG! I didn\\'t mean to!\" Then he tells mom not to say anything to the police about it. Kid was killed under a scarecrow, though. So, like any kid who gets murdered under a scarecrow, he comes back as a killer scarecrow with a vengeance. His victims \"haven\\'t been stalked like this before...\" (Scarecrow\\'s official tag line)To make matters worse, this movie was filmed in a whopping 8 days. That\\'s right, 8 days. I was going to give this movie a 2, because in spite of itself, it has one or two redeeming moments. (They\\'re spoilers, so I won\\'t spoil it for you, if you actually want to see this crap.) I could have somewhat forgiven the bad acting, the horrible special effects, the abysmal script, and the bad camera work, but I simply have no respect for lack of effort on that level.This movie isn\\'t nearly as good as I\\'m making it out to be. If you want to see an example of how not to make a movie, or if you enjoy watching bad movies, like I do, then watch this at your own risk. Everyone else should stay a safe distance away from this movie at all times.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eight',\n",
       " 'should',\n",
       " 'though',\n",
       " 'at',\n",
       " 'made',\n",
       " 'eg',\n",
       " 'most',\n",
       " 'rather',\n",
       " 'will',\n",
       " 'yourselves']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "list(ENGLISH_STOP_WORDS)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=5, stop_words=ENGLISH_STOP_WORDS)\n",
    "# cv = CountVectorizer(min_df=5, stop_words=\"english\")\n",
    "\n",
    "cv.fit(X_train2)\n",
    "X_train3 = cv.transform(X_train2)\n",
    "X_test3 = cv.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9852, 0.8574)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, C=0.1)\n",
    "lr.fit(X_train3,y_train2)\n",
    "lr.score(X_train3,y_train2), lr.score(X_test3, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈도 계산 방법 (p.429)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "tv = TfidfVectorizer(min_df=5) # 단어의 상대빈도 계산(단어빈도/문서빈도)\n",
    "tv.fit(X_train2)\n",
    "X_train3=tv.transform(X_train2)\n",
    "X_test3= tv.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.996, 0.8692)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, C=10)\n",
    "lr.fit(X_train3, y_train2)\n",
    "lr.score(X_train3,y_train2), lr.score(X_test3, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화, 어간추출,표제어추출 (p438)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy # 표제어 사전 관리도구 설치\n",
    "# !python -m spacy download en # 영어 표제어 사전 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer() # 어간추출기\n",
    "en_nlp = spacy.load('en') # 영어 표제어 사전 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = u\"Our meeting today was worse than yesterday, I'm scared of meeting the clients tomorrow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어:  ['-PRON-', 'meeting', 'today', 'be', 'bad', 'than', 'yesterday', ',', '-PRON-', 'be', 'scared', 'of', 'meet', 'the', 'client', 'tomorrow']\n",
      "정규화 표현:  ['our', 'meeting', 'today', 'was', 'worse', 'than', 'yesterday', ',', 'i', 'am', 'scared', 'of', 'meeting', 'the', 'clients', 'tomorrow']\n",
      "어간:  ['our', 'meet', 'today', 'wa', 'wors', 'than', 'yesterday', ',', 'i', 'am', 'scare', 'of', 'meet', 'the', 'client', 'tomorrow']\n"
     ]
    }
   ],
   "source": [
    "spacy_doc = en_nlp(data)\n",
    "# print(\"분리된 단어 목록: \" , [token for token in spacy_doc])   # 형태소 분리된 단어 목록 출력\n",
    "print(\"표제어: \" , [token.lemma_ for token in spacy_doc]) # 개별 단어의 표제어 출력\n",
    "print(\"정규화 표현: \" , [token.norm_ for token in spacy_doc])  # 개별 단어의 정규화 표현 출력\n",
    "print(\"어간: \" , [stemmer.stem(token.norm_) for token in spacy_doc])  #개별 단어의 어간 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# regexp = re.compile('(?u)\\b\\w\\w+\\b') #\n",
    "\n",
    "# def custom_tokenizer(scr):\n",
    "#     from spacy.tokens import Doc\n",
    "#     doc = Doc(en_nlp.vocab, words=regexp.findall(scr))\n",
    "#     return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files('data-files/aclImdb/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = reviews_train['data'], reviews_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 [12623, 24836, 13781, 1326, 8484] 5000\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "size = int(len(X_train) * 0.2)            # 25000건중 20%만 자르는 과정\n",
    "# idxes = np.random.randint(0, len(X_train), size)  # 0부터 X_train갯수 까지중 size만큼 랜덤으로 뽑는다. 20% 데이터 샘플링 (복원추출)\n",
    "idxes = random.sample(range(len(X_train)), size)  # 랜덤으로 추출 // 20% 데이터 샘플링(비복원추출)\n",
    "print( len(idxes), idxes[:5], len(np.unique(idxes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000,), (5000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2, y_train2 = np.array(X_train)[idxes], np.array(y_train)[idxes]\n",
    "X_train2.shape, y_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Friz Freleng's 'Speedy Gonzalez' was the second cartoon to feature the title character after Robert McKimson's 'Cat-tails for Two'. In that cartoon, Speedy has been an ugly little creature with a big gold tooth but by his second appearance the famous design had already been adopted. Despite looking significantly more handsome, Speedy never developed into much of a character. A big hat, tremendous speed and a bad Mexican accent do not a classic character make and that's pretty much all Speedy ever had going for him. Nevertheless, the cocky little mouse proved enormously popular and went on to star in many shorts including some truly abysmal films from the studio's latter days. While these early Speedy shorts are better than those later atrocities in which he was frequently (rather oddly) paired up with Daffy Duck, they still leave much to be desired, relying on predictable gags usually based around a similar chase formula. In this self-titled episode, Speedy is recruited by some other mice to steal cheese for them from the local factory which happens to be guarded by Sylvester the cat. Although he brings the extra weight of a star turn to the cartoon, Sylvester's role here could just as easily been filled by any other generic cartoon cat. His personality is sapped by his being forced into the predictable. undemanding role of pursuer. This was always a problem in the Tweety cartoons too but Speedy makes an even duller adversary thanks to his detestable cockiness and the blatant impossibility of his capture. Poor old Sylvester would be forced to appear alongside Speedy for many years to come. Despite it following a pretty basic formula and featuring minimal laughs, 'Speedy Gonzalez' won an Oscar and a thoroughly undeserving star was born.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2[1]   #데이터가 html로 되어 있음. <br /><br />\n",
    "X_train2 = np.array([x.replace(b'<br />', b'') for x in X_train2])   #반복문 돌리며 진행(내포방식)     #자바스크립트 정규표현식 참조할것!\n",
    "# 또는 아래방식으로도 진행 가능\n",
    "# X_train22 = map(lambda x : x.replace(b'<br />', b''), X_train2)  \n",
    "# X_train2 = np.array(list(X_train2))\n",
    "\n",
    "X_train2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files('data-files/aclImdb/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = reviews_test['data'], reviews_test['target']\n",
    "size = int(len(X_test) * 0.2 )\n",
    "idxes = random.sample(range(len(X_test)),size)\n",
    "len(np.unique(idxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = np.array( [X_test[idx] for idx in idxes])\n",
    "y_test2 = np.array( [y_test[idx] for idx in idxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = np.array([ x.replace(b'<br />', b'') for x in X_test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"What a great film! I never knew much about Buddy Holly, but was familiar with his lively and fun music. This is a wonderful biography of someone who helped change the music in the 1950's. Although I never cared for Gary Bussey, he was fabulous as Buddy Holly! I don't know how accurate the movie is, but assume at least for the most part it is accurate, which makes the movie all the more interesting. The music throughout the movie just adds the pizazz to this biography. I don't think I would change a thing in this film, it was all good! What a difference in the stars from the 50's to todays music stars. How can you compare someone like Buddy Holly to Justin Timberlake? or any of the other popular singers of this generation?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "regexp = re.compile('(?u)\\\\b\\\\w\\\\w+\\\\b') # (r'(?u)\\b\\w\\w+\\b')\n",
    "\n",
    "def custom_tokenizer(scr):\n",
    "    from spacy.tokens import Doc\n",
    "    doc = Doc(en_nlp.vocab, words=regexp.findall(scr))\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=custom_tokenizer, min_df=5)\n",
    "cv.fit(X_train2)\n",
    "X_train3 = cv.transform(X_train2)\n",
    "X_test3 = cv.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9784 0.8588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, C=0.1)\n",
    "lr.fit(X_train3, y_train2)\n",
    "print(lr.score(X_train3, y_train2), lr.score(X_test3, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
